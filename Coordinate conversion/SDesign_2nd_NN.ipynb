{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import csv\n",
    "import numpy as np\n",
    "import SD2_Model as SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 1, 5]              15\n",
      "            Linear-2                 [-1, 1, 5]              30\n",
      "            Linear-3                 [-1, 1, 5]              30\n",
      "            Linear-4                 [-1, 1, 5]              30\n",
      "            Linear-5                 [-1, 1, 2]              12\n",
      "================================================================\n",
      "Total params: 117\n",
      "Trainable params: 117\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#net = SD.Net()\n",
    "device = torch.device(\"cuda\") \n",
    "net = SD.Net().to(device)\n",
    "summary(net, input_size = (1,2))\n",
    "#print(net)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#dummy data\n",
    "#trainset = (torch.rand(2,1, device=\"cuda\"), torch.rand(2,1, device=\"cuda\") ) #Xs and Ys\n",
    "trainset = torch.tensor([[1,2],[3,4]]).to(device)\n",
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([253., 151.], device='cuda:0') tensor([ 0.4324, -2.2259], device='cuda:0')\n",
      "tensor([ 2.4662, -3.9144], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "%dataT = readtable('2NN_dataset_flight.5.csv');\n",
    "\n",
    "\n",
    "Load_data = True\n",
    "dataset_path = \"../2NN_dataset_flight.3.csv\"\n",
    "if(Load_data):\n",
    "    trainset = []\n",
    "    with open(dataset_path) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            #feature, data_label = int(row[0:2]),row[2:4]\n",
    "            feature, data_label = (int(row[0]),int(row[1])),(float(row[2]) * 100 ,float(row[3]) * 100) #convert to cm\n",
    "            #feature, data_label = (int(row[0]),int(row[1])),(round(float(row[2]) * 100) ,round(float(row[3]) * 100)) #convert to cm\n",
    "            trainset.append([feature, data_label])\n",
    "            #print([feature, data_label])\n",
    "\n",
    "trainset = torch.Tensor(trainset).to(device)\n",
    "#print(trainset)\n",
    "\n",
    "test_data = True\n",
    "if(test_data):\n",
    "    #trainset = np.array(trainset)\n",
    "    #print(trainset[1])\n",
    "    feature, data_label = trainset[0]\n",
    "    print(feature, data_label)\n",
    "    #print(feature.view(1,2))\n",
    "    output = net(feature)\n",
    "    print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(404.5726, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "1 tensor(67.1429, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "2 tensor(9.3985, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "3 tensor(1.2907, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "4 tensor(0.7562, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "5 tensor(1.8798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "6 tensor(2.8915, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "7 tensor(1.3447, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "8 tensor(0.9659, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "9 tensor(2.2211, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "10 tensor(1.6516, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "11 tensor(0.0245, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "12 tensor(2.0634, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "13 tensor(3.3412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "14 tensor(3.4014, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "15 tensor(0.4632, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "16 tensor(3.4341, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "17 tensor(3.0221, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "18 tensor(7.1127, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "19 tensor(1.9938, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "20 tensor(2.4337, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "21 tensor(2.5778, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "22 tensor(2.8863, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "23 tensor(2.1534, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "24 tensor(1.9650, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "25 tensor(1.1353, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "26 tensor(1.6075, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "27 tensor(1.7825, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "28 tensor(1.7841, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "29 tensor(1.5426, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "30 tensor(0.5679, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "31 tensor(0.2397, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "32 tensor(0.1892, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "33 tensor(0.1473, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "34 tensor(0.0892, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "35 tensor(0.1390, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "36 tensor(0.0932, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "37 tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "38 tensor(0.0416, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "39 tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "40 tensor(0.1988, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "41 tensor(0.2517, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "42 tensor(0.2671, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "43 tensor(0.1495, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "44 tensor(0.1792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "45 tensor(0.1634, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "46 tensor(0.1550, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "47 tensor(0.3239, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "48 tensor(0.2664, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "49 tensor(0.1781, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "50 tensor(0.4238, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "51 tensor(0.2244, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "52 tensor(0.2711, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "53 tensor(0.2561, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "54 tensor(0.3337, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "55 tensor(0.3020, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "56 tensor(0.3048, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "57 tensor(0.3130, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "58 tensor(0.1903, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "59 tensor(0.2868, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "60 tensor(0.3009, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "61 tensor(0.3126, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "62 tensor(0.1676, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "63 tensor(0.2864, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "64 tensor(0.2909, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "65 tensor(0.2106, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "66 tensor(0.4222, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "67 tensor(0.1465, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "68 tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "69 tensor(0.1101, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "70 tensor(0.1477, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "71 tensor(0.4201, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "72 tensor(1.4942, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "73 tensor(1.2878, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "74 tensor(1.0577, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "75 tensor(0.9560, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "76 tensor(0.9133, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "77 tensor(0.8985, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "78 tensor(1.0750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "79 tensor(1.1080, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "80 tensor(0.9975, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "81 tensor(0.9563, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "82 tensor(1.1783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "83 tensor(1.0514, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "84 tensor(1.2339, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "85 tensor(1.2080, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "86 tensor(0.7543, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "87 tensor(1.0972, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "88 tensor(0.9693, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "89 tensor(0.9540, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "90 tensor(0.9560, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "91 tensor(0.9270, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "92 tensor(1.0335, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "93 tensor(0.8484, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "94 tensor(0.8020, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "95 tensor(1.3684, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "96 tensor(0.1501, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "97 tensor(0.2827, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "98 tensor(0.3587, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "99 tensor(0.4598, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "0.459766149520874\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "epochs = 100\n",
    "best_loss = 0.0\n",
    "if (train):\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        for data in trainset:  \n",
    "            feature, data_label = data #\n",
    "            #print(data)\n",
    "            #print(feature)\n",
    "            #print(data_label)\n",
    "            net.zero_grad()  \n",
    "            output = net(feature)\n",
    "            loss = loss_function(output, data_label) \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "        print(epoch,loss)\n",
    "        if(epoch == 1):\n",
    "            best_loss = loss.item()\n",
    "        if(loss.item() < best_loss or loss.item() < 1.0):\n",
    "            best_loss = loss.item()\n",
    "            best_save = \"./models_saves/best_2nd_NN_\"\n",
    "            torch.save(net, best_save + str(epoch) + \"_\" + str(round(best_loss,5)) +\".pt\")\n",
    "    print(best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save network\n",
    "save = True\n",
    "#save = False\n",
    "model_save_path = \"2nd_NN.pt\"\n",
    "if (save):\n",
    "    torch.save(net, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test evaluate\n",
    "\n",
    "Load_eval = False\n",
    "if(Load_eval):\n",
    "    #model = SD.Net().to(device)\n",
    "    net = torch.load(model_save_path)\n",
    "    net.eval()\n",
    "\n",
    "dataset_path = \"../2NN_dataset_flight.2.csv\"\n",
    "if(False):\n",
    "    net.eval()\n",
    "    eval_data = []\n",
    "    with open(dataset_path) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            #feature, data_label = int(row[0:2]),row[2:4]\n",
    "            feature, data_label = (int(row[0]),int(row[1])),(float(row[2]) * 100 ,float(row[3]) * 100) #convert to cm\n",
    "            #feature, data_label = (int(row[0]),int(row[1])),(round(float(row[2]) * 100) ,round(float(row[3]) * 100)) #convert to cm\n",
    "            net(feature)\n",
    "            eval_data.append([feature, data_label])\n",
    "            \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58dc188af903f85495c8c8ba2d08d4f5901f4034aea6d9dbb2f8641074b88212"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('191T_py3': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
