{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import csv\n",
    "import numpy as np\n",
    "import SD2_Model as SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 20]              60\n",
      "            Linear-2                [-1, 1, 20]             420\n",
      "            Linear-3                 [-1, 1, 2]              42\n",
      "================================================================\n",
      "Total params: 522\n",
      "Trainable params: 522\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net = SD.Net()\n",
    "device = torch.device(\"cuda\") \n",
    "net = SD.Net().to(device)\n",
    "summary(net, input_size = (1,2))\n",
    "#print(net)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#dummy data\n",
    "#trainset = (torch.rand(2,1, device=\"cuda\"), torch.rand(2,1, device=\"cuda\") ) #Xs and Ys\n",
    "trainset = torch.tensor([[1,2],[3,4]]).to(device)\n",
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([256., 153.], device='cuda:0') tensor([ 1.1746, -0.1598], device='cuda:0')\n",
      "tensor([ 6.3309, -7.3105], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Load_data = True\n",
    "dataset_path = \"../2NN_dataset_flight.2.csv\"\n",
    "if(Load_data):\n",
    "    trainset = []\n",
    "    with open(dataset_path) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            #feature, data_label = int(row[0:2]),row[2:4]\n",
    "            feature, data_label = (int(row[0]),int(row[1])),(float(row[2]) * 100 ,float(row[3]) * 100) #convert to cm\n",
    "            #feature, data_label = (int(row[0]),int(row[1])),(round(float(row[2]) * 100) ,round(float(row[3]) * 100)) #convert to cm\n",
    "            trainset.append([feature, data_label])\n",
    "            #print([feature, data_label])\n",
    "\n",
    "trainset = torch.Tensor(trainset).to(device)\n",
    "#print(trainset)\n",
    "\n",
    "test_data = True\n",
    "if(test_data):\n",
    "    #trainset = np.array(trainset)\n",
    "    #print(trainset[1])\n",
    "    feature, data_label = trainset[0]\n",
    "    print(feature, data_label)\n",
    "    #print(feature.view(1,2))\n",
    "    output = net(feature)\n",
    "    print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(267.6589, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "1 tensor(262.2520, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "2 tensor(278.2845, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "3 tensor(218.1288, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "4 tensor(209.9195, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "5 tensor(240.1874, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "6 tensor(251.6852, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "7 tensor(253.5984, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "8 tensor(244.6513, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "9 tensor(244.3012, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "10 tensor(231.6703, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "11 tensor(192.5672, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "12 tensor(79.4979, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "13 tensor(60.1432, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "14 tensor(48.4920, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "15 tensor(178.5667, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "16 tensor(169.6997, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "17 tensor(135.6661, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "18 tensor(113.0134, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "19 tensor(93.4711, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "20 tensor(77.3081, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "21 tensor(65.9336, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "22 tensor(56.3124, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "23 tensor(48.2525, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "24 tensor(41.5667, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "25 tensor(35.9952, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "26 tensor(32.0634, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "27 tensor(28.7214, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "28 tensor(0.3114, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "29 tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "30 tensor(0.1207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "31 tensor(8.2919, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "32 tensor(4.3676, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "33 tensor(1.8298, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "34 tensor(2.3721, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "35 tensor(3.2698, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "36 tensor(3.6609, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "37 tensor(5.2918, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "38 tensor(5.9667, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "39 tensor(5.9568, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "40 tensor(5.9485, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "41 tensor(5.9990, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "42 tensor(6.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "43 tensor(5.9385, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "44 tensor(6.9144, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "45 tensor(5.8844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "46 tensor(5.7184, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "47 tensor(5.5484, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "48 tensor(5.4733, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "49 tensor(5.3064, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "50 tensor(5.3627, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "51 tensor(5.5206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "52 tensor(5.2911, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "53 tensor(5.0520, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "54 tensor(5.2322, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "55 tensor(4.9277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "56 tensor(6.5697, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "57 tensor(6.6852, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "58 tensor(7.0714, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "59 tensor(6.5222, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "60 tensor(5.9152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "61 tensor(5.6531, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "62 tensor(5.3649, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "63 tensor(5.3200, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "64 tensor(4.9190, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "65 tensor(4.9350, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "66 tensor(5.1024, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "67 tensor(5.2000, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "68 tensor(3.3538, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "69 tensor(3.8007, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "70 tensor(3.4101, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "71 tensor(3.6399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "72 tensor(3.3884, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "73 tensor(3.3286, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "74 tensor(3.1809, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "75 tensor(2.4678, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "76 tensor(2.3571, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "77 tensor(4.8468, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "78 tensor(8.0582, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "79 tensor(12.2701, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "80 tensor(6.2106, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "81 tensor(7.0459, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "82 tensor(9.4014, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "83 tensor(1.3122, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "84 tensor(6.6405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "85 tensor(4.3186, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "86 tensor(3.7568, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "87 tensor(10.4645, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "88 tensor(3.0382, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "89 tensor(4.1082, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "90 tensor(4.8766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "91 tensor(4.8647, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "92 tensor(4.6397, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "93 tensor(4.5765, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "94 tensor(4.5143, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "95 tensor(3.4157, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "96 tensor(3.9460, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "97 tensor(3.0339, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "98 tensor(3.5891, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "99 tensor(3.5921, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "100 tensor(2.9246, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "101 tensor(3.5435, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "102 tensor(3.3000, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "103 tensor(4.0773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "104 tensor(3.0573, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "105 tensor(5.1952, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "106 tensor(3.0695, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "107 tensor(3.8506, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "108 tensor(3.4738, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "109 tensor(1.7596, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "110 tensor(2.0329, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "111 tensor(1.9986, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "112 tensor(1.3005, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "113 tensor(2.3385, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "114 tensor(2.6207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "115 tensor(1.8711, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "116 tensor(2.4726, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "117 tensor(3.0496, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "118 tensor(1.1108, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "119 tensor(2.4902, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "120 tensor(2.8753, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "121 tensor(4.1050, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "122 tensor(7.0217, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "123 tensor(9.1246, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "124 tensor(9.7322, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "125 tensor(11.2359, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "126 tensor(9.4074, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "127 tensor(9.1251, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "128 tensor(7.7639, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "129 tensor(6.9604, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "130 tensor(7.5058, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "131 tensor(8.6169, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "132 tensor(9.1578, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "133 tensor(9.1621, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "134 tensor(9.4651, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "135 tensor(9.5165, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "136 tensor(9.9822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "137 tensor(9.9863, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "138 tensor(9.9651, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "139 tensor(10.0952, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "140 tensor(10.4089, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "141 tensor(10.3603, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "142 tensor(10.3022, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "143 tensor(10.7302, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "144 tensor(10.5024, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "145 tensor(10.6147, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "146 tensor(10.3214, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "147 tensor(10.9301, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "148 tensor(10.7388, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "149 tensor(13.1693, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "150 tensor(10.4067, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "151 tensor(9.4837, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "152 tensor(8.9832, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "153 tensor(8.8500, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "154 tensor(8.4519, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "155 tensor(8.2492, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "156 tensor(8.0534, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "157 tensor(7.8745, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "158 tensor(8.4997, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "159 tensor(8.3687, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "160 tensor(8.5401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "161 tensor(9.4582, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "162 tensor(8.4400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "163 tensor(8.2196, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "164 tensor(8.6265, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "165 tensor(8.8483, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "166 tensor(8.9595, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "167 tensor(9.2585, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "168 tensor(8.9979, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "169 tensor(9.0675, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "170 tensor(9.4312, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "171 tensor(9.8130, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "172 tensor(10.2191, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "173 tensor(10.7314, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "174 tensor(11.1414, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "175 tensor(10.9018, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "176 tensor(10.7972, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "177 tensor(11.1737, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "178 tensor(11.1641, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "179 tensor(10.9175, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "180 tensor(11.1530, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "181 tensor(11.6558, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "182 tensor(11.5595, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "183 tensor(11.9867, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "184 tensor(12.1707, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "185 tensor(11.7973, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "186 tensor(10.8583, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "187 tensor(11.2274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "188 tensor(12.3259, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "189 tensor(13.8971, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "190 tensor(14.1839, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "191 tensor(13.9273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "192 tensor(14.0769, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "193 tensor(13.6718, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "194 tensor(14.2302, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "195 tensor(12.9976, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "196 tensor(13.5755, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "197 tensor(11.9321, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "198 tensor(11.2631, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "199 tensor(11.0527, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "epochs = 200\n",
    "if (train):\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        for data in trainset:  \n",
    "            feature, data_label = data #\n",
    "            #print(data)\n",
    "            #print(feature)\n",
    "            #print(data_label)\n",
    "            net.zero_grad()  \n",
    "            output = net(feature)\n",
    "            loss = loss_function(output, data_label) \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "        print(epoch,loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save network\n",
    "#save = True\n",
    "save = False\n",
    "model_save_path = \"2nd_NN.pt\"\n",
    "if (save):\n",
    "    torch.save(net, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test evaluate\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58dc188af903f85495c8c8ba2d08d4f5901f4034aea6d9dbb2f8641074b88212"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('191T_py3': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
